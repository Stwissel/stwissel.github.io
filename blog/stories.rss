<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
<channel>
	<title>wissel.net Usability - Productivity - Business - The web - Singapore and Twins</title>
	<link>https://wissel.net/blog/stories.rss</link>
	<description>Thoughts, Insights and Opinions of Stephan H. Wissel. Topics included: IBM Lotus Notes and Domino, IBM Websphere, other IBM Lotus stuff,  J2EE, .Net, Software Archtecture, Personcentric Development, Agile Software, SDLC, Singapore and my Twins</description>
	<language>en,de</language>
	<copyright>(C) 2003 - 2017 Stephan H. Wissel, All rights reserved</copyright>
	<pubdate>Sun, 26 Mar 2017 04:24:28 +0800</pubdate>
<item>
	<title>Agile Outsourcing</title>
	<description>&lt;h2&gt;The problem&lt;/h2&gt; 
&lt;a href="http://www.investopedia.com/terms/o/outsourcing.asp"&gt;Outsourcing&lt;/a&gt; is a &amp;quot;special&amp;quot; animal. Typically the idea is to save cost by letting a service provider execute work. The saving cost happens because the service provider is supposed to be able to perform this actions at scale. Increasingly outsourcing deals are motivated by a skill squeeze. So instead of maintaining in-house expertise, rely on the vendors to keep the light on. 
&lt;br /&gt; This is where the trouble starts. Negotiations on outsourcing contracts revolves around price (drive it down) and the 
&lt;a href="https://en.wikipedia.org/wiki/Service-level_agreement"&gt;SLA&lt;/a&gt; (add as many 9 behind the comma as possible). The single outcome of such contracts is extreme risk aversion. For illustration here is the impact of SLA levels : 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;SLA&lt;/th&gt; 
   &lt;th&gt;Total annual Downtime&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;98%&lt;/td&gt; 
   &lt;td&gt;7 days, 6h, 12min&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;99%&lt;/td&gt; 
   &lt;td&gt;3 days, 15h, 36min&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;99.9%&lt;/td&gt; 
   &lt;td&gt;8h, 45min, 36sec&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;99.99%&lt;/td&gt; 
   &lt;td&gt;52min, 34sec&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;99.999%&lt;/td&gt; 
   &lt;td&gt;5min, 16sec&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;99.9999%&lt;/td&gt; 
   &lt;td&gt;32 sec&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; The fixation on SLA has a clinical term: 
&lt;a href="https://en.wikipedia.org/wiki/Obsessive%E2%80%93compulsive_disorder"&gt;OCD&lt;/a&gt;. Any change is considered as dangerous as someone holding a knife at your throat and asked you to dance. 
&lt;br /&gt; Looking at some of the figures (I can't share) I would claim that short of highly parallel (and expensive) transaction system anything above 99.9% is wishful thinking. That doesn't deter negotiators to aim for a &amp;quot;look how many 9th I got&amp;quot; trophy. (While the Buddha reminds us: one cause of suffering is to close your eyes to reality). Expensive SLA violation clauses let outsourcers freeze all system, since any change (read: patches, upgrades, enhancements) is 
&lt;a href="http://www.statuscast.com/application-downtime-according-to-idc-gartner-and-others/"&gt;rightly identified&lt;/a&gt; as grave risk (to the profits). 
&lt;br /&gt; So all sorts of processes and checks get implemented to vet any change request and in practise avoid them. 
&lt;br /&gt; This usually leads to a lot of bureaucracy and glacial progress. As a result discontent, especially on the use of non-transactional system grows: Stuff like outdated eMail clients, lack of mobile support etc. etc. 
&lt;br /&gt; The relation between oursourcer and oursourcee grows, inevitably, challenging over time. Does it have to be that way? 
&lt;h2&gt;Some fresh thinking&lt;/h2&gt; Just move to cloud might not be the answer (or everybody would be there, it's 
&lt;a href="http://www.networkworld.com/article/3020235/cloud-computing/and-the-cloud-provider-with-the-best-uptime-in-2015-is.html"&gt;such a nice place&lt;/a&gt;). So what could be done? Here are some thoughts: 
&lt;ul&gt; 
 &lt;li&gt;Kiss goodby the wholesale SLA agreement. Classify systems based on business impact. A booking system for an airline surly deserves three nines (I doubt that four would make sense), while a website can live with one nine (as long as it distributed over the year)&lt;/li&gt; 
 &lt;li&gt;Take a page from the PaaS offerings: each element of the environment has a measurement and a price. So the outsourcing provider can offer ala card services instead of freezing the environment. A catalogue entry could be &amp;quot;Running a current and patched DB/2&amp;quot;, another entry could be &amp;quot;Run a legacy IIS, version xx&amp;quot;&lt;/li&gt; 
 &lt;li&gt;Customer and provider would agree on an annual catalogue value, based on the starting environment and any known plan at the time&lt;/li&gt; 
 &lt;li&gt;The catalogue would allow to decommission unneeded system and replace them with successors without much hassle (out with PHP, in with node.js)&lt;/li&gt; 
 &lt;li&gt;Automate, Automate, Automate - An outsourcer without DevOps (Puppet, Chef and tight monitoring) didn't get the 2017 message&lt;/li&gt; 
 &lt;li&gt;Transparency: Running systems over processes, Customer satisfaction over unrealistic SLA, Automation over documentation (I hear the howling), Repeatable procedures over locked down environments&lt;/li&gt; 
&lt;/ul&gt; What do you think?</description>
	<link>2017/02/agile-outsourcing.html</link>
	<author>Stephan H Wissel</author>
	<guid>28D047097AAD822D482580C1003C6EF8</guid>
	<pubDate>2017-02-08 07:00</pubDate>

</item>
<item>
	<title>SAML and the Command Line</title>
	<description>One of the best kept secrets of Connections Cloud S1 is the 
&lt;a href="https://www-10.lotus.com/ldd/dominowiki.nsf/dx/IBM_Notes_Traveler_Administration_API"&gt;Traveler API&lt;/a&gt;. The API allows interactions that are missing from the Admin UI, like deleting a specific device or implementing an approval workflow. 
&lt;br /&gt; Unfortunately the API only offers authentication via SAML, OAuth or BasicAuth are missing. So any application interacting with the API needs to do 
&lt;a href="https://www.google.com.sg/search?q=SAML+Dance+Connections+Cloud"&gt;The SAML Dance&lt;/a&gt;. That's annoying when you have an UI to use, and a formidable challenge when you have a command line application, like a cron Job running unsupervised at interval. 
&lt;br /&gt; One lovely step in the process: the IBM IdP returns a HTML page with a hidden form containing the SAML assertion result to be posted back to the application provider. Quite interesting, when your application provider is a command line app. Let's get to work. 
&lt;br /&gt; The script is written in 
&lt;a href="https://nodejs.org"&gt;node.js&lt;/a&gt; and uses 
&lt;a href="https://www.npmjs.com/package/request"&gt;request&lt;/a&gt; and 
&lt;a href="https://www.npmjs.com/package/fast-html-parser"&gt;fast-html-parser&lt;/a&gt; npm package. The first step is to load the login form (which comes with a first set of cookies) 
&lt;br /&gt; 
&lt;pre class="brush: js"&gt;
var requestOptionsTemplate = {
    headers: {
        'Origin': 'https://api.notes.ap.collabserv.com/api/traveler/',
        'User-Agent': 'ancy CommandLine Script',
        'Connection': 'keep-alive',
        'Cache-Control': 'max-age=0',
        'Upgrade-Insecure-Requests': 1
    },
    'method': 'GET'
};

function scLoginPart1() {
    console.log('Authenticating to SmartCloud ...');
    var requestOptions = Object.assign({}, requestOptionsTemplate);
    requestOptions.url = 'https://apps.na.collabserv.com/manage/account/dashboardHandler/input';
    request(requestOptions, scLoginPart2);
}
&lt;/pre&gt; 
&lt;br /&gt; The function calls the URL where the login form can be found. The result gets delivered to the function 
&lt;code&gt;scLoginPart2&lt;/code&gt;. That function makes use of a global configuration variable 
&lt;code&gt;config&lt;/code&gt; that was created through 
&lt;code&gt;const config = require(&amp;quot;./config.json&amp;quot;)&lt;/code&gt; and contains all the credentials we need. Step2 submits the form and hands over to Step3. 
&lt;br /&gt; 
&lt;pre class="brush: js"&gt;
function scLoginPart2(err, httpResponse, body) {
    if (err) {
        return console.error(err);
    }
    // Capture cookies
    var outgoingCookies = captureCookies(httpResponse);
    var requestOptions = Object.assign({}, requestOptionsTemplate);
    requestOptions.headers.Cookie = outgoingCookies.join('; ');
    requestOptions.headers['Content-Type'] = 'application/x-www-form-urlencoded';
    requestOptions.method = 'POST';
    requestOptions.url = 'https://apps.ap.collabserv.com/pkmslogin.form';
    requestOptions.form = {
        'login-form-type': 'pwd',
        'error-code': '',
        'username': config.smartcloud.user,
        'password': config.smartcloud.password,
        'show_login': 'showLoginAgain'
    }
    request(requestOptions, scLoginPart3);
}

function captureCookies(response) {
    var incomingCookies = response.headers['set-cookie'];
    var outgoingCookies = [];
    if (incomingCookies) {
        incomingCookies.forEach(function(cookie) {
            outgoingCookies.push(cookie.split(';')[0]);
        });
    }
    // Array, allows for duplicate coolie names
    return outgoingCookies;
}
&lt;/pre&gt; 
&lt;br /&gt; Part 3 / 4 finally collect all the cookies we need, so to turn attention to getting the API token in step 5 
&lt;br /&gt; 
&lt;pre class="brush: js"&gt;
function scLoginPart3(err, httpResponse, body) {
    if (err) {
        console.error('Login failed miserably');
        return console.error(err);
    }
    // Login returns not 200 but 302
    // see https://developer.ibm.com/social/2015/06/23/slight-changes-to-the-form-based-login/
    if (httpResponse.statusCode !== 302) {
        return console.error('Wrong status code received: ' + httpResponse.statusCode);
    }

    var outgoingCookies = captureCookies(httpResponse);
    var redirect = httpResponse.headers.location;

    // This is the 3rd request we need to make to get finally all cookies for app.na
    var requestOptions = Object.assign({}, requestOptionsTemplate);
    requestOptions.headers.Cookie = outgoingCookies.join('; ');
    requestOptions.url = redirect;
    request(requestOptions, scLoginPart4);
}

function scLoginPart4(err, httpResponse, body) {
    if (err) {
        console.error('Login redirect failed miserably');
        return console.error(err);
    }
    var cookieHarvest = captureCookies(httpResponse);
    // Now we have some cookies in app, we need the SAML dance for api.notes
    scLoginPart5(cookieHarvest)
}
&lt;/pre&gt; 
&lt;br /&gt; In Part 5 we first request the URL with actual data (devices in our case), but get another SAML dance step, since we have 
&lt;code&gt;apps.na&lt;/code&gt; vs 
&lt;code&gt;api.notes&lt;/code&gt; in the URL</description>
	<link>2017/01/saml-and-the-command-line.html</link>
	<author>Stephan H Wissel</author>
	<guid>134DE77E2F5D7C55482580B8004B2B1E</guid>
	<pubDate>2017-01-30 09:41</pubDate>

</item>
<item>
	<title>GIT deploy your static sites - Part 1</title>
	<description>When you, in principal, like the idea to 
&lt;a href="/blog/d6plinks/SHWL-AHHBPB"&gt;serve SPA from the http server&lt;/a&gt;, you will encounter the pressing question: 
&lt;strike&gt;
  where do babies come from 
&lt;/strike&gt; how to get your application deployed onto the http server? This applies to nodeJS applications too, but that is part of another story for another time. 
&lt;br /&gt; On 
&lt;a href="https://console.ng.bluemix.net/"&gt;Bluemix&lt;/a&gt; that's easy: just use a 
&lt;a href="https://hub.jazz.net/docs/deploy/#example"&gt;Pipeline&lt;/a&gt;. 
&lt;br /&gt; For mere mortal environments there are several options: 
&lt;ul&gt; 
 &lt;li&gt;Just FTP them - insecure unless you use sftp/scp. Big pain here: deleting obsolete files&lt;/li&gt; 
 &lt;li&gt;Setup rsync. When done with a ssh certificate can be reasonably automated. Same pain applies: deleting obsolete files&lt;/li&gt; 
 &lt;li&gt;Use a &lt;a href="https://git-scm.com/"&gt;GIT&lt;/a&gt; based deployment. This is what I will discuss further&lt;/li&gt; 
&lt;/ul&gt; I like a repository based deployment since it fits nicely into a development based workflow. The various git gui tools provide insight what has changed between releases and if things go wrong, you can roll back to a previous version or you can wipe data and reestablish them from the repository. Designing the flow, I considered the following constraints: 
&lt;ul&gt; 
 &lt;li&gt;The repositories would sit on the web server&lt;/li&gt; 
 &lt;li&gt;Typically a repository would sit in &lt;code&gt;.git&lt;/code&gt; inside the site directory. While you could protect that with access control, I decided I don't want to have it in separate directories&lt;/li&gt; 
 &lt;li&gt;When pushing to the &lt;code&gt;master&lt;/code&gt; branch, the site should get updated, not on any other branch. You can extend my approach to push other branches to other sites - so you get a test/demo/staging capability&lt;/li&gt; 
 &lt;li&gt;Setting up a new site should be fast and reliable (including https - but that's part 2)&lt;/li&gt; 
&lt;/ul&gt; The &amp;quot;secret&amp;quot; ingredients here are 
&lt;a href="https://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks#Server-Side-Hooks"&gt;git-hooks&lt;/a&gt;, in specific the 
&lt;code&gt;post-receive&lt;/code&gt;. Hooks, in a nutshell are shell scripts that are triggered by events that happen to a git environment. I got inspired by 
&lt;a href="http://nicolasgallagher.com/simple-git-deployment-strategy-for-static-sites/"&gt;this entry&lt;/a&gt; but wanted to automate the setup.</description>
	<link>2017/01/git-deploy-your-static-sites-part-1.html</link>
	<author>Stephan H Wissel</author>
	<guid>016311C01DE0239E482580A600186343</guid>
	<pubDate>2017-01-12 12:26</pubDate>

</item>
<item>
	<title>Serving Single Page Applications with Domino</title>
	<description>&lt;a href="https://en.wikipedia.org/wiki/Single-page_application"&gt;Single Page Applications&lt;/a&gt; (SPA) are all the rage. They get developed with AngularJS, ReactJS or {insert-your-framework-of-choice}. Those share a few communialities: 
&lt;ul&gt; 
 &lt;li&gt;the application is served by a static web server&lt;/li&gt; 
 &lt;li&gt;data is provided via an API, typically reading/writing JSON via REST or graph&lt;/li&gt; 
 &lt;li&gt;authentication is often long lasting (remember me...) based on &lt;a href="https://jwt.io/"&gt;JWT&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;authentication is highly flexible: login with {facebook|google|linkedin|twitter} or a corporate account. Increasingly 2 factor authentication is used (especially &lt;a href="http://eur-lex.europa.eu/eli/reg/2016/679/oj"&gt;in Europe&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; How does Domino fit into the picture with its integrated http stack, authentication and database? The answer isn't very straight forward. Bundling components creates ease of administration, but carries the risk that new technologies are implemented late (or not at all). For anything internet facing that's quite some risk. So here is what I would do: 
&lt;br /&gt; 
&lt;img src="/blog/images/2017/DominoAPIServer.jpg" border="0" alt="Red/Green Zone layout for Domino" /&gt; 
&lt;br /&gt;</description>
	<link>2017/01/serving-single-page-applications-with-domino.html</link>
	<author>Stephan H Wissel</author>
	<guid>9B9FB2E6D097996C482580A5002D4E39</guid>
	<pubDate>2017-01-11 04:14</pubDate>

</item>
<item>
	<title>Lessons from Project OrangeBox</title>
	<description>&lt;p&gt;Project OrangeBox, the &lt;a href="http://lucene.apache.org/solr/"&gt;Solr&lt;/a&gt; free search component, was launched after the experiments with Java8, &lt;a href="http://vertx.io/"&gt;Vert.x&lt;/a&gt; and &lt;a href="https://github.com/ReactiveX/RxJava"&gt;RxJava&lt;/a&gt; in &lt;a href="#" title="The project that shall not be named" style="color: black; font-weight: normal"&gt;TPTSNBN&lt;/a&gt; concluded. With &lt;a href="https://twitter.com/edbrill/status/799733973870059520"&gt;a certain promise&lt;/a&gt; we were working on a tight dead line and burned way more midnight oil than I would have wished for.&lt;/p&gt; 
&lt;p&gt;Anyway, I had the opportunity to work with great engineers and we shipped as promised. There are quite some lesson to be learned, here we go (in no specific order):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;b&gt;Co-locate&lt;/b&gt;&lt;br /&gt; The Verse team is spread over the globe: USA, Ireland, Belarus, China, Singapore and The Philippines. While this allows for 24x7 development, it also poses a substantial communications overhead. We made the largest jumps in both features and quality during and after co-location periods. So any sizable project needs to start and be interluded with co-location time. Team velocity will greatly benefit&lt;/li&gt; 
 &lt;li&gt;&lt;b&gt;No holy cows&lt;/b&gt;&lt;br /&gt; For VoP we slaughtered the &amp;quot;Verse is Solr&amp;quot; cow. That saved the Domino installed base a lot of investments in time and resources. Each project has its &amp;quot;holy cows&amp;quot;: Interfaces, tool sets, &amp;quot;invaluable, immutable code&amp;quot;, development pattern, processes. You have to be ready to challenge them by keeping a razor sharp focus on customer success. Watch out for Prima donnas (see next item)&lt;/li&gt; 
 &lt;li&gt;&lt;b&gt;No &lt;a href="https://www.google.com.sg/search?q=define+primadonna"&gt;Prima Donnas&lt;/a&gt;&lt;/b&gt;&lt;br /&gt; As software engineers we are very prone to perceive our view of the world as the (only) correct one. After all we create some of it. In a team setting that's deadly. Self reflection and &lt;a href="http://www.planetofsuccess.com/blog/2011/developing-empathy-walk-a-mile-in-someone%E2%80%99s-shoes/"&gt;empathy&lt;/a&gt; are as critical to the success as technical skills and perseverance.&lt;br /&gt; &lt;a href="http://amzn.to/2ixejLi"&gt;Robert Sutton&lt;/a&gt;, one of my favourite Harvard authors, expresses that &lt;a href="http://amzn.to/2j2ljD1"&gt;a little bolder&lt;/a&gt;.&lt;br /&gt; In short: A team can only be bigger than the sum of its members, when the individuals see themselves as members and are not hovering above it&lt;/li&gt; 
 &lt;li&gt;&lt;b&gt;Unit test are overrated&lt;/b&gt;&lt;br /&gt; I hear howling, read on. Like &amp;quot;A journey of &lt;a href="http://www.bbc.co.uk/worldservice/learningenglish/movingwords/shortlist/laotzu.shtml"&gt;a thousand miles&lt;/a&gt; begins with a single step&amp;quot; you can say: &amp;quot;Great software starts with a Unit Test&amp;quot;. Begins, not: &amp;quot;Great software consists of Unit Tests&amp;quot;. A great journey that only has steps ends tragically in death by starvation, thirst or evil events.&lt;br /&gt; Same applies to your test regime: You start with Unit tests, write code, pass it on to the next level of tests (module, integration, UI) etc. So unit tests are a &amp;quot;&lt;a href="https://en.wikipedia.org/wiki/Sine_qua_non"&gt;conditio sine qua non&lt;/a&gt;&amp;quot; in your test regime, but in no way sufficient&lt;/li&gt; 
 &lt;li&gt;&lt;b&gt;Test pyramid and good test data&lt;/b&gt;&lt;br /&gt; Starting with unit tests (we used &lt;a href="http://junit.org/"&gt;JUnit&lt;/a&gt; and &lt;a href="http://easymock.org/"&gt;EasyMock&lt;/a&gt;), you move up to module tests. There, still written in JUnit, you check the correctness of higher combinations. Then you have API test for your REST API. Here we used &lt;a href="https://www.getpostman.com/"&gt;Postman&lt;/a&gt; and its node.js integration &lt;a href="https://www.getpostman.com/docs/newman_intro"&gt;Newman&lt;/a&gt;.&lt;br /&gt; Finally you need to test end-to-end including the UI. For that &lt;a href="http://www.seleniumhq.org/"&gt;Selenium&lt;/a&gt; rules supreme. Why not e.g. &lt;a href="http://phantomjs.org/"&gt;PhantomJS&lt;/a&gt;? Selenium drives real browsers, so you can (automate) test against all rendering engines, which, as a fact of the matter, behave unsurprisingly different.&lt;br /&gt; One super critical insight: You need a &lt;b&gt;good set&lt;/b&gt; of diverse test data, both expected and unexpected inputs in conjunction with the expected outputs. A good set of &lt;b&gt;fringe data&lt;/b&gt; makes sure you catch challenges and border conditions early.&lt;br /&gt; Last not least: Have performance tests from the very beginning. We used both &lt;a href="http://www-03.ibm.com/software/products/en/performance"&gt;Rational Performance Tester&lt;/a&gt; (RPT) and &lt;a href="http://jmeter.apache.org/"&gt;Apache JMeter&lt;/a&gt;. RPT gives you a head start in creating tests, while JMeter's XML file based test cases were easier to share and manipulate. When you are short of test infrastructure (quite often the client running tests is the limiting factor) you can offload JMeter tests to &lt;a href="https://www.blazemeter.com/"&gt;Blazemeter&lt;/a&gt; or &lt;a href="https://flood.io/"&gt;Flood.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;b&gt;Measure, measure, measure&lt;/b&gt;&lt;br /&gt; You need to know where your code is spending its time in. We employed a number of tools to get good metrics. You want to look at averages, min, max and standard deviations of your calls. David even wrote a specific plugin to see the native calls (note open, design note open) or Java code would produce (This will result in future Java API improvements). The two main tools (besides watching the network tab in the browser) were &lt;a href="https://newrelic.com/"&gt;New Relic&lt;/a&gt; with deep instrumentation into our Domino server's JVM and &lt;a href="http://jamonapi.sourceforge.net/"&gt;JAMon&lt;/a&gt; collecting live statistics (which you can query on the Domino console using &lt;code&gt;show stats vop&lt;/code&gt;. Making measurements a default practise during code development makes your life much easier later on&lt;/li&gt; 
 &lt;li&gt;&lt;b&gt;No Work without ticket&lt;/b&gt;&lt;br /&gt; That might be the hardest part to implement. Any code item needs to be related to a ticket. For the search component we used Github Enterprise, pimped up with &lt;a href="https://www.zenhub.com/"&gt;Zenhub&lt;/a&gt;.&lt;br /&gt; A &lt;b&gt;very&lt;/b&gt; typical flow is: someone (analyst, scrum master, offering manager, project architect, etc.) &amp;quot;owns&amp;quot; the ticket system and tickets flow down. Sounds awfully like &lt;a href="http://www.waterfall2006.com/"&gt;waterfall&lt;/a&gt; (and it is). Breaking free from this and turn to &amp;quot;the tickets are created by the developers and are the actual standup&amp;quot; greatly improves team velocity. This doesn't preclude creation of tickets by others, to fill a backlog or create and extend user stories. Look for the middle ground.&lt;br /&gt; We managed to get Github tickets to &lt;a href="http://marketplace.eclipse.org/content/github-mylyn-connector"&gt;work with Eclipse&lt;/a&gt; which made it easy to create tickets on the fly. Once you are there you can visualize progress using &lt;a href="http://www.wissel.net/blog/d6plinks/SHWL-8CLNBW"&gt;Burn charts&lt;/a&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;b&gt;Agile&lt;/b&gt;&lt;br /&gt; &amp;quot;Standup meeting every morning 9:30, no exception&amp;quot; - isn't agile. That's process strangling velocity. Spend some time to rediscover &lt;a href="http://alistair.cockburn.us/Rediscovering+the+Heart+of+Agile"&gt;the heart of Agile&lt;/a&gt; and implement that.&lt;br /&gt; Typical traps to avoid: 
  &lt;ul&gt; 
   &lt;li&gt;use ticket (closings) as (sole) metric. It only discourages the us of the ticket system as ongoing documentation&lt;/li&gt; 
   &lt;li&gt;insist on process over collaboration. A &amp;quot;standup meeting&amp;quot; could be just a Slack channel for most of the time. No need to spend time every day in a call or meeting, especially when the team is large&lt;/li&gt; 
   &lt;li&gt;Code is final - it's not. Refactoring is part of the package - including refactoring the various tests&lt;/li&gt; 
   &lt;li&gt;Isolate teams. If there isn't a lively exchange of progress, you end up with silo code. Requires mutual team respect&lt;/li&gt; 
   &lt;li&gt;Track &amp;quot;percent complete&amp;quot;. This lives on the fallacy of 100% being a fixed value. Track units of work left to do (and expect that to eventually rise during the project)&lt;/li&gt; 
   &lt;li&gt;One way flow. If the people actually writing code can't participate in shaping user stories or create tickets, you have waterfall in disguise&lt;/li&gt; 
   &lt;li&gt;Narrow user definitions and stories: I always cringe at the Scrum template for user stories: &amp;quot;As a ... I want ... because/in order to ...&amp;quot;. There are two fallacies: first it presumes a linear, single actor flow, secondly it only describes what happens if it works. While it's a good start, adopting more complete use cases (the big brother of user stories) helps to keep the stories consistent. Go learn about &lt;a href="http://amzn.to/2iCBDtM"&gt;Writing Effective Use Cases&lt;/a&gt;. The agile twist: A use case doesn't have to be complete to get started. Adjust and complete it as it evolves. Another little trap: The &amp;quot;users&amp;quot; in the user stories need to include: infrastructure managers, db admins, code maintainer, software testers etc. Basically anybody touching the app, not just final (business) users&lt;/li&gt; 
   &lt;li&gt;No code reviews: looking at each other's code increases coherence in code style and accellerates bug squashing. Don't fall for the trap: productivity drops by 50% if 2 people stare at one screen - just the opposite happens&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;b&gt;Big screens&lt;/b&gt;&lt;br /&gt; While co-located we 
  &lt;strike&gt;
    squatted in 
  &lt;/strike&gt; booked conference rooms with whiteboard, postit walls and projectors. Some of the most efficient working hours were two or three pairs of eyes walking through code, both in source and debug mode. During quiet time (developers need ample of that. The &lt;a href="http://amzn.to/2iCLMXc"&gt;Bose solution&lt;/a&gt; isn't enough), 27&amp;quot; or more inches of screen real estate boost productivity. At my home office I run a dual screen setup with more than one machine running (However, I have to admit: some of the code was written perched into a cattle class seat travelling between Singapore and the US)&lt;/li&gt; 
 &lt;li&gt;&lt;b&gt;Automate&lt;/b&gt;&lt;br /&gt; We used both &lt;a href="https://jenkins.io/" title="Jenkins is the tool of choice for the core Verse team"&gt;Jenkins&lt;/a&gt; and &lt;a href="https://travis-ci.org/" title="ISSC uses Travis, mostly because it also can build on macOS"&gt;Travis&lt;/a&gt; as our automation platform. The project used &lt;a href="http://maven.apache.org/"&gt;Maven&lt;/a&gt; to keep the project together. While Maven &lt;a href="https://en.wikipedia.org/wiki/The_Moon_Is_a_Harsh_Mistress"&gt;is a harsh mistress&lt;/a&gt; spending time to provide all automation targets proved invaluable.&lt;br /&gt; You have to configure your test regime carefully. Unit test should not only run on the CI environment, but on a developers workstation - for the code (s)he touches. A full integration test for VoP on the other hand, runs for a couple of hours. That's the task better left to the CI environment. Our Maven tasks included generating the (internal) website and the JavaDoc.&lt;br /&gt; Lesson learned: setting up a full CI environment is quite a task. Getting the repeatable datasets in place (especially when you have time sensitive tests like &amp;quot;provide emails from the last hour&amp;quot;) can be tricky. Lesson 2: you will need more compute than expected, plan for parallel testing &lt;/li&gt; 
 &lt;li&gt;&lt;b&gt;Ownership&lt;/b&gt;&lt;br /&gt; David owned performance, Michael the build process, Raj the Query Parser, Christopher the test automation and myself the query strategy and core classes. It didn't mean: being the (l)only coder, but feeling responsible and taking the lead in the specific module. With the sense of ownership at the code level, we experienced a number of refactoring exercises, to the benefit of the result, that would never have happened if we followed &lt;a href="https://www.youtube.com/watch?v=qYodWEKCuGg"&gt;Code Monkey&lt;/a&gt; style an analyst's or architect's blueprint. &lt;/li&gt; 
&lt;/ul&gt; As usual YMMV</description>
	<link>2017/01/lessons-from-project-orangebox.html</link>
	<author>Stephan H Wissel</author>
	<guid>ECA77946958C5E624825809D0009F1B0</guid>
	<pubDate>2017-01-03 09:48</pubDate>

</item>
<item>
	<title>The totally inofficial guide to Verse on Premises</title>
	<description>&lt;p&gt;Now that &lt;a href="http://www-01.ibm.com/support/docview.wss?uid=swg24043176"&gt;CNGD8ML&lt;/a&gt; is upon us, it is story time. Read about the why, who, what and what to watch out for.&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;To successfully deploy Verse, make sure to carefully read and implement &lt;a href="https://www.ibm.com/support/knowledgecenter/SS4RQV_1.0.0/admin/topics/vop_configuring_server.html"&gt;&lt;b&gt;the installation instructions&lt;/b&gt;&lt;/a&gt;. The availability of Verse makes Domino the most versatile eMail platform around, offering you the choice of: Notes Client, Outlook, POP2, IMAP4, iNotes, Verse, iOS, Android. Anywhay, here we go:&lt;/p&gt; 
&lt;h2&gt;The back story&lt;/h2&gt; 
&lt;p&gt;Verse on premises was a long (out)standing promise to the IBM customer base. Not everybody is ready to embrace the cloud, but interested in &lt;a href="https://twitter.com/search?f=tweets&amp;amp;vertical=default&amp;amp;q=%23newwaytowork&amp;amp;src=typd"&gt;the new way to work&lt;/a&gt;. In SmartCloud Notes, the backend for Verse in the Cloud, all search is powered by &lt;a href="http://lucene.apache.org/solr/"&gt;Apache SOLR&lt;/a&gt;. If Verse got delivered as is, that would have required substantial hardware and skill investments for the on-premises customers.&lt;/p&gt; 
&lt;p&gt; So I made a bet with &lt;a href="https://www.linkedin.com/in/michaelguyalexander"&gt;Michael Alexander&lt;/a&gt;, whom I worked with on TPTSNBN, that we could use standard Domino capabilities, not requiring Solr. Based on prototypes with &lt;a href="http://vertx.io/"&gt;vert.x&lt;/a&gt; and Java8 we gained confidence and got the go ahead to build the search component as OSGi plug-in (in Java6). So the search part (not the UI or other functionality) is on me.&lt;/p&gt; 
&lt;h2&gt;The team(s)&lt;/h2&gt; 
&lt;p&gt;There were two distinct teams working on the delivery of Verse on Premises (VoP): The core Verse team, that owns UI, functionality and features for both cloud and on premises and the search plugin team responsible to replace the Solr capabilities with native Domino calls. &lt;br /&gt;The former is rather large, distributed between the US, Ireland and China. The later was led by the distinguished engineer &lt;a href="https://www.linkedin.com/in/david-byrd-401668a"&gt;David Byrd&lt;/a&gt; and just a few core coding members: David, Michael, &lt;a href="https://www.linkedin.com/in/cheltzel"&gt;Christopher&lt;/a&gt;, &lt;a href="https://sg.linkedin.com/in/raj-j-rajendran-226a9456"&gt;Raj&lt;/a&gt; and myself.&lt;br /&gt; We were supported by a team of testers in Belarus and the Philippines. The test teams wrote hundreds of &lt;a href="http://junit.org/"&gt;JUnit&lt;/a&gt; and &lt;a href="https://www.getpostman.com/"&gt;Postman&lt;/a&gt; tests, just for the search API.&lt;/p&gt; 
&lt;h2&gt;The Orangebox&lt;/h2&gt; 
&lt;p&gt;Each project needs a good &lt;a href="#" title="A nice one: TPTSNBN = The Project That Shall Not Be Named"&gt;code name&lt;/a&gt;. The original Verse code name was &lt;a href="https://en.wikipedia.org/wiki/Sequoia_National_Park "&gt;Sequoia&lt;/a&gt;, which is reflected in the name of the plugins for core and UI functionality.&lt;/p&gt; 
&lt;p&gt;The search component, not being part of RealVerse™, needed a different name. In an initial high level diagram, outlining the architecture for management, the search component was drawn as an orange box. Since we &amp;quot;just&amp;quot; had to code &amp;quot;the orange box&amp;quot;. The name stuck and led to our code name &amp;quot;Project OrangeBox&amp;quot; (PoB). &lt;br /&gt;&lt;img src="/blog/images/2016/OrangeBox.png" border="0 " alt="The inofficial Project Orange Box Logo" /&gt; &lt;br /&gt; You &lt;a href="http://jd.benow.ca/ " title="Don 't do this, it is most likely illegal" rel="nofollow"&gt;can find&lt;/a&gt; Orangebox and POB in multiple places (including notes.ini variables and https calls the browser makes). So now you know where it is coming from.&lt;/p&gt;</description>
	<link>2016/12/the-totally-inofficial-guide-to-verse-on-premises.html</link>
	<author>Stephan H Wissel</author>
	<guid>C11DBB777E01D4AB4825809600019630</guid>
	<pubDate>2016-12-30 08:17</pubDate>

</item>
<item>
	<title>Domino meets RXJava</title>
	<description>Verse on premises (VoP) is nearing its second beta release and fellow Notes experts are wondering if they need to install 
&lt;a href="http://lucene.apache.org/solr/"&gt;Apache Solr&lt;/a&gt; as part of the VoP deployment. There was a lengthy, high quality discussion and quite some effort evaluating alternatives. In conclusion it was decided to deliver the subset of Solr capabilities needed for VoP as series of OSGi plugins to the Domino server. The project was formed out of the experience with ProjectCastle, which continues as Project OrangeBox to deliver these plugins. In VoP you might encounter one or the other reference to PoB, so now you know where it comes from. 
&lt;br /&gt; One of the design challenges to solve was to emulate the facet results of the Solr search engine. I build some prototypes and finally settled on the use of 
&lt;a href="https://github.com/ReactiveX/RxJava"&gt;RxJava&lt;/a&gt;. 
&lt;br /&gt; RxJava is a member of the 
&lt;a href="http://reactivex.io/"&gt;ReactiveX&lt;/a&gt; programming family, which is designed around the Observer pattern, iterators and functional programming. Check out the 
&lt;a href="http://reactivex.io/"&gt;main site&lt;/a&gt; to get into the groove. 
&lt;br /&gt; The task at hand is to convert something Domino (a ViewNavigator, a DocumentCollection or a Document) into something that emits subscribable events. I started with turning a document into an NotesItem emitter. Purpose of this was the creation of lighweight Java objects that contain the items I'm interested in. Since Domino's Java has 
&lt;a href="http://www-01.ibm.com/support/docview.wss?uid=swg21097861"&gt;special needs&lt;/a&gt; and I couldn't use the 
&lt;a href="https://github.com/OpenNTF/org.openntf.domino"&gt;ODA&lt;/a&gt;, special precaution was needed. 
&lt;br /&gt; There are 
&lt;a href="https://github.com/ReactiveX/RxJava/wiki/Creating-Observables"&gt;plenty of methods&lt;/a&gt; to create an Observable and on first look 
&lt;a href="http://reactivex.io/documentation/operators/create.html"&gt;Create&lt;/a&gt; looks most promising, but it left the question of recycling open. Luckily there is the 
&lt;a href="http://reactivex.io/documentation/operators/using.html"&gt;Using&lt;/a&gt; method that creates a companion object that lives along the Observable and gets explicitly called when the Observable is done. To create the NotesItem emitting Observable I settled on the 
&lt;a href="http://reactivex.io/documentation/operators/from.html"&gt;From&lt;/a&gt; method with an 
&lt;a href="https://docs.oracle.com/javase/7/docs/api/java/lang/Iterable.html"&gt;Iterable&lt;/a&gt; as source. The moving parts I had to create were 
&lt;code&gt;class DocumentSource implements Iterable&amp;lt;Item&amp;gt;&lt;/code&gt; and 
&lt;code&gt;class ItemIterator implements Iterator&amp;lt;Item&amp;gt;&lt;/code&gt; 
&lt;br /&gt; Why Reactive? In a nutshell: a source emits data and any number of subscribers can subscribe to. Between the emission and subscription any number of filters, modifiers and aggregators can manipulate the data emitted. Since each of them lives in its own little class, testing and composition become very easy. Let's look at an example: 
&lt;br /&gt; 
&lt;code&gt;docSource.getItemStream(session).filter(nameFilter).map(toPobItem).map(nameMapper).subscribe(new ItemAdder());&lt;/code&gt; 
&lt;br /&gt; You almost can read this aloud: &amp;quot; 
&lt;i&gt;The source emits a stream of items, they get filtered by Name, then converted into another Java object (PobItem) and renamed before added to the subscriber.&lt;/i&gt;&amp;quot;. In a different case you might want to collect all entities (users, groups, roles) that have access to a document, you migh create a &amp;quot;readerAuthorFilter&amp;quot;. The individual classes are very easy to test. E.g. the Name filter looks like this: 
&lt;br /&gt; 
&lt;pre class="brush: java"&gt;
// requiredFields is is a Collection&amp;lt;String&amp;gt; of NotesItem names to include or exclude
ItemNameFilter nameFilter = new ItemNameFilter(requiredFields, ItemNameFilter.FilterMode.INCLUDE);

public class ItemNameFilter implements Func1&amp;lt;Item, Boolean&amp;gt; {

    public enum FilterMode {
        INCLUDE, EXCLUDE;
    }

    private final Logger      logger      = Logger.getLogger(this.getClass().getName());
    private final Set&amp;lt;String&amp;gt; itemNameSet = new HashSet&amp;lt;String&amp;gt;();
    private final FilterMode  filterMode;

    /**
     * Flexible include or exclude
     * 
     * @param itemNames
     *            Collection of Names to include or exclude
     * @param filterMode
     *            INCLUDE or EXCLUDE
     */
    public ItemNameFilter(Collection&amp;lt;String&amp;gt; itemNames, FilterMode filterMode) {
        this.filterMode = filterMode;
        this.updateItemNames(itemNames);
    }

    public ItemNameFilter(Collection&amp;lt;String&amp;gt; itemNames) {
        this.filterMode = FilterMode.INCLUDE;
        this.updateItemNames(itemNames);
    }

    private void updateItemNames(Collection&amp;lt;String&amp;gt; itemNames) {
        this.itemNameSet.addAll(itemNames);
    }

    @Override
    public Boolean call(Item incomingItem) {
        // Include unless proven otherwise
        boolean result = true;
        try {
            String itemName = incomingItem.getName();
            boolean inList = this.itemNameSet.contains(itemName.toLowerCase());
            result = (inList &amp;amp;&amp;amp; this.filterMode.equals(FilterMode.INCLUDE));
        } catch (NotesException e) {
            this.logger.log(Level.SEVERE, e);
            result = false;
        }
        return result;
    }
}
&lt;/pre&gt; 
&lt;br /&gt;</description>
	<link>2016/09/domino-meets-rxjava.html</link>
	<author>Stephan H Wissel</author>
	<guid>770F2C2B080A75A84825802D001E8D87</guid>
	<pubDate>2016-09-13 01:33</pubDate>

</item>
<item>
	<title>Metawork, nobody is capable but all participate grudgingly</title>
	<description>This article is a translation/paraphrase of Professor Gunter Dueck's original post titled 
&lt;a href="http://www.omnisophie.com/dd265-metawork-keiner-kanns-aber-alle-machen-aergerlich-mit-mai-2016/"&gt;DD265: Metawork – keiner kann’s, aber alle machen &amp;auml;rgerlich mit (Mai 2016)&lt;/a&gt;. Professor Dueck's 
&lt;a href="/blog/d6plinks/SHWL-8MGKRK"&gt;philosophy&lt;/a&gt; resonates with me, so I'd like to make his thoughts available to a wider audience. Bear with my Gerlish. Remarks in brackets aren't part of the original text and are either my comment, extension or explanation. Here we go: 
&lt;br /&gt; 
&lt;br /&gt; Metawork is your own effort to organize work (your's and other's), not performing the actual effort. It is about coordinating your contributions, more often than not, across multiple projects. This includes managing decisions (through eMail) and the communicate with all stakeholders. E.g. you can use efficient (Dueck used the word &amp;quot;fertile&amp;quot;, but I'm not sure if that has the same resonance in English) meetings to establish the approach how to structure and execute working together. Over time a corporate culture emerges where a common good metawork forms the enabler for efficient execution of the core work (we'll learn another term for this just below). 
&lt;br /&gt; 
&lt;br /&gt; In reality, however, there are quarrels in meetings, about who does what. Conflicts surface, everyone speaks their minds unfiltered, meetings drag on and on. People get a grudge and are annoyed and are left with the feeling to have wasted valuable time, they won't get back. Dueck checked the web, what it has to say about metawork. His favorite place is the the 
&lt;a href="http://www.urbandictionary.com/define.php?term=metawork"&gt;Urban Dictionary&lt;/a&gt; &amp;nbsp;where ordinary people contribute to difficult definitions and provide lots of suggestions. The best of them are the odd ones. 
&lt;br /&gt; 
&lt;br /&gt; You rant online to be overburdened with unproductive responsibilities, unable to get anything done. People share that in a development project staffed with eight people only two of them code. The rest warms seats in the meeting room and is first in line for promotion if the project is successful. What a mess! 
&lt;br /&gt; 
&lt;br /&gt; Hmmm. So your own work is productive, anything else a distraction. Not thinking about what your project members see as their &amp;quot;productive work&amp;quot;. An example: If the developers miss a deadline, it generates a lot of distraction for the rest of the team. &amp;quot;Everything would be perfect if the coders would work properly! We have to integrate into SAP, everybody is waiting. What a cluster f**k (that's the closest cultural equivalent to &amp;quot;Supergau&amp;quot; I could think of)&amp;quot; - The two developers retort: &amp;quot;You could have contributed code, instead of babbling in all that meeting, we would be done by now&amp;quot; 
&lt;br /&gt; 
&lt;br /&gt; This a clear indicator, Dueck sees in all corporations, that the different project members have no understanding of the tasks of their fellow members. If they do know them, they doubt the importance or usefulness. One's own work is important, anything else is a distraction. Others only interrupt. Then they quarrel in in meetings 
&lt;br /&gt; 
&lt;br /&gt; &amp;nbsp; Why oh why? All are well trained for their own tasks and complete them quite well. However roughly none have been educated on metawork: how to get organized and collaborate. They do some of it every day, limping along without having or wanting to learn about it. It never had been a topic.&amp;nbsp;They bitch the whole day about the drag of metawork without being able to fully grasp it, lacking a word for it, not aware of the term metawork. Managers and project leaders follow the prevalent methodologies and press forward. More often than not, they aren't aware of metawork. The manage or lead as &amp;quot;their own work&amp;quot;, but hardly spend a thought on the work as a whole 
&lt;br /&gt; 
&lt;br /&gt; Even when managers would know how to coordinate well and fuse the parts to a whole, how to deal with unknowns and avoid conflict - it falls short when their reports have no clue what is metawork? 
&lt;br /&gt; 
&lt;br /&gt; When team members only spend half of their time with &amp;quot;their own work (e.g. programming)&amp;quot; and &amp;nbsp;are irate about the &amp;quot;stolen&amp;quot; time spend in meetings otherwise, they haven't understood the very nature of work - or metawork is done mind-boggling bad. 
&lt;br /&gt; 
&lt;br /&gt; Metawork is about the principles and foundation of performing work. Those who haven't given it a thought, bungle in each project, wondering how it could work. Every conflict is new, different and unique. Each project has its own singular surprises. What a madhouse! Lots of literature reenforces that point of view. 
&lt;br /&gt; However that's because one only focuses on their own tasks at hand, and never learn to pay respect of the significant other contributions. 
&lt;br /&gt; 
&lt;br /&gt; Dueck suggested in his book „Verst&amp;auml;ndigung im Turm zu Babel“ (Communicate in the tower of Babel) and his blog to contrast meta communication and mesa communication. „Mesa“ is greek meaning „inside“, „meta“ is like „and beyond“. In the context of work „mesawork“ would be the individual task at hand and „metawork“ anything beyond that. Dueck sees it over and over again: Nobody is really good at meta communication, anybody communicates off their chests. Similarly we are good at mesawork but bemoan the complexity of the world, since we can't relate to metawork. 
&lt;br /&gt; 
&lt;br /&gt; Shall we leave it that way? Half of our time being experts, half of it clueless N00bs? Isn't the balance tipping towards cluelessness, since the need for metawork is raising in a increasingly complex world? How about you? Happy to continue only fretting?</description>
	<link>2016/05/metawork-nobody-is-capable-but-all-participate-grudgingly.html</link>
	<author>Stephan H Wissel</author>
	<guid>014D0E91EC01C33748257FB1008223B0</guid>
	<pubDate>2016-05-13 07:41</pubDate>

</item>
<item>
	<title>Mach Dich auf die Socken!</title>
	<description>A common requirement in corporate systems is &amp;quot;let me know when something is going on&amp;quot;. In Notes we use &amp;quot;On document creation or update&amp;quot; triggered agents to process such events. To let external systems know about such a change R8 introduced the web service client. This works well in distributed system, but requires quite some work on both ends. In a recent case I had to optimize the communication between Domino and a task running on the same machine. The existing solution was polling the Domino API in short intervals for updates. Something I would call 
&lt;a href="https://www.youtube.com/watch?v=basofea2UEs"&gt;donkey mode&lt;/a&gt;. Sockets to the rescue. A few lines of Java in a triggered agent puts an end to donkey mode and provides the receiving end with all it needs in time: 
&lt;br /&gt; 
&lt;pre 'brush:="" java'=""&gt;
import java.io.BufferedReader;
import java.io.DataOutputStream;
import java.io.IOException;
import java.io.InputStreamReader;
import java.net.Socket;

import lotus.domino.AgentBase;
import lotus.domino.AgentContext;
import lotus.domino.Database;
import lotus.domino.Document;
import lotus.domino.DocumentCollection;
import lotus.domino.NotesException;
import lotus.domino.Session;

import com.issc.castle.domino.Utils;

public class JavaAgent extends AgentBase {

	public static String	sockethost	= &amp;quot;127.0.0.1&amp;quot;;
	public static int		socketport	= 1234;

	public void NotesMain() {
		Session session = null;
		AgentContext agentContext = null;
		Database db = null;
		DocumentCollection dc = null;
		Document doc = null;

		// The socket elements
		DataOutputStream out = null;
		BufferedReader in = null;
		Socket socketClient = null;
		try {
			// Get the Notes parts
			session = getSession();
			agentContext = session.getAgentContext();
			db = agentContext.getCurrentDatabase();
			dc = agentContext.getUnprocessedDocuments();

			// Get the socket
			socketClient = new Socket(sockethost, socketport);
			in = new BufferedReader(new InputStreamReader(socketClient.getInputStream()));
			out = new DataOutputStream(socketClient.getOutputStream());

			doc = dc.getFirstDocument();
			while (doc != null) {
				Document nextDoc = dc.getNextDocument(doc);
				this.signalOneDocument(doc, in, out);
				Utils.shred(doc);
				doc = nextDoc;
			}

			// Mark them done
			dc.updateAll();
		} catch (Exception e) {
			e.printStackTrace();
		} finally {
			Utils.shred(doc, dc, db, agentContext, session);
			// Close them
			try {
				if (out != null) {
					out.close();
				}
				if (in != null) {
					in.close();
				}
				if (socketClient != null) {
					socketClient.close();
				}
			} catch (IOException e) {
				e.printStackTrace();
			}
		}
	}

	private void signalOneDocument(final Document doc, final BufferedReader in, final DataOutputStream out) {
		try {
			String notesURL = doc.getNotesURL();
			out.writeBytes(notesURL);
			out.writeBytes(&amp;quot;|&amp;quot;);
		} catch (NotesException e) {
			e.printStackTrace();
		} catch (IOException e) {
			e.printStackTrace();
		}

	}
}
&lt;/pre&gt; 
&lt;br /&gt; No libraries to load, the only utility function used is 
&lt;code&gt;Utils.shred()&lt;/code&gt; which is a error wrapped recycle call. 
&lt;br /&gt; As usual YMMV 
&lt;br /&gt; (Bad German pun in the title)</description>
	<link>2016/05/mach-dich-auf-die-socken.html</link>
	<author>Stephan H Wissel</author>
	<guid>9D58015278C7504F48257FAE00512380</guid>
	<pubDate>2016-05-09 10:46</pubDate>

</item>
<item>
	<title>Annotations to supercharge your vert.x development</title>
	<description>ProjectCastle is well under way. Part of it, the part talking to Domino, is written in Java8 and 
&lt;a href="http://vertx.io"&gt;vert.x&lt;/a&gt;. With some prior experience in node.js development vert.x will look familiar: base on event loop and callbacks, you develop in a very similar way. The big differences: vert.x runs on the JVM8, it is by nature of the JVM multi-threaded, features an event bus and is polyglot - you can develop in a mix of languages: Java, JavaScript, Jython, Groovy etc. 
&lt;br /&gt; This post reflects some of the approaches I found useful developing with vert.x in Java. There are 3 components which are core to vert.x development: 
&lt;ul&gt; 
 &lt;li&gt;&lt;h4&gt;Verticle&lt;/h4&gt; A unit of compute running with an event loop. Usually you start one Verticle (optional with multiple instances) as your application, but you might want/need to start additional ones for longer running tasks. A special version is the worker verticle, that runs from a thread pool to allow execution of blocking operations&lt;/li&gt; 
 &lt;li&gt;&lt;h4&gt;EventBus&lt;/h4&gt; The different components of your application message each other via the EventBus. Data send over the EventBus can be a String, a JsonObject or a buffer. You also can send any arbitrary Java class as message once you have defined a codec for it &lt;/li&gt; 
 &lt;li&gt;&lt;h4&gt;Route&lt;/h4&gt; Like in node.js a vert.x web application can register routes and their handlers to react on web input under various conditions. Routes can be defined using URLs, HTTP Verbs, Content-Types ( for POST/PUT/PATCH operations)&lt;/li&gt; 
&lt;/ul&gt; Ideally when defining a route and a handler, a verticle or a potential message for the EventBus, all necessary code stays contained in the respective source code file. The challenge here is to register the components when the application starts. Your main Verticle doesn't know what components are in your application and manually maintain a loader code is a pain to keep in sync (besides leading to merge conflicts when working in a team). 
&lt;br /&gt; Java annotations to the rescue! If you are new to annotations, go and check out 
&lt;a href=""&gt;this tutorial&lt;/a&gt; to get up to speed. For my project I defined three of them, with one being able to be applied multiple times. 
&lt;h3&gt;CastleRequest&lt;/h3&gt; A class annotated with CastleRequest registers its handler with the EventBus, so the class can be sent over the EventBus and get encoded/decode appropriately. A special value for the annotation is &amp;quot;self&amp;quot; which indicates, that the class itself implements the 
&lt;a href="http://vertx.io/docs/apidocs/io/vertx/core/eventbus/MessageCodec.html"&gt;MessageCodec&lt;/a&gt; interface 
&lt;br /&gt; 
&lt;pre 'brush:="" java'=""&gt;
@Documented
@Retention(RetentionPolicy.RUNTIME)
@Target({ElementType.TYPE})
public @interface CastleRequest {
  // We use value to ease the syntax
  // to @CastleRequest(NameOfCodec)
  // Special value: self = class implements the MessageCodec interface
  String value();
}
&lt;/pre&gt; 
&lt;h3&gt;CastleRoute&lt;/h3&gt; This annotation can be assigned multiple times, so 2 annotation interfaces are needed 
&lt;br /&gt; 
&lt;pre 'brush:="" java'=""&gt;
@Documented
@Repeatable(CastleRoutes.class)
@Retention(RetentionPolicy.RUNTIME)
@Target({ElementType.TYPE})
public @interface CastleRoute {
  String route();
  String description();
  String mimetype() default &amp;quot;any&amp;quot;;
  String method() default &amp;quot;any&amp;quot;;
}
&lt;/pre&gt; 
&lt;br /&gt; and the repeatability annotation (new with Java8): 
&lt;br /&gt; 
&lt;pre 'brush:="" java'=""&gt;
@Documented
@Retention(RetentionPolicy.RUNTIME)
@Target({ElementType.TYPE})
public @interface CastleRoutes {
  CastleRoute[] value();
}
&lt;/pre&gt; 
&lt;h3&gt;CastleVerticle&lt;/h3&gt; Classes marked with this annotation are loaded as verticles. They can implement listeners to the whole spectrum of vert.x listening capabilities 
&lt;br /&gt; 
&lt;pre 'brush:="" java'=""&gt;
@Documented
@Retention(RetentionPolicy.RUNTIME)
@Target({ElementType.TYPE})
public @interface CastleVerticle {
  String type() default &amp;quot;worker&amp;quot;;
  int instances() default 0;
  boolean multithreaded() default false;
}
&lt;/pre&gt;</description>
	<link>2016/04/annotations-to-supercharge-your-vertx-development.html</link>
	<author>Stephan H Wissel</author>
	<guid>30DE462FC074A36C48257F89000019CB</guid>
	<pubDate>2016-04-02 08:01</pubDate>

</item>

</channel>
</rss>
